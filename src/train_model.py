import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
import joblib

def main():
    """
    Train and evaluate a logistic regression model for fraud detection.
    """
    try:
        # Load preprocessed datasets
        print("Loading datasets...")
        train_data = pd.read_csv("../data/fraudTrain.csv")
        test_data = pd.read_csv("../data/fraudTest.csv")

        # Convert 'trans_date_trans_time' to datetime and drop it
        print("Processing date-time column...")
        train_data["trans_date_trans_time"] = pd.to_datetime(train_data["trans_date_trans_time"])
        test_data["trans_date_trans_time"] = pd.to_datetime(test_data["trans_date_trans_time"])
        train_data.drop(columns=["trans_date_trans_time"], inplace=True)
        test_data.drop(columns=["trans_date_trans_time"], inplace=True)

        print("Preprocessing completed successfully.")

        # Drop unnecessary columns
        train_data.drop(columns=["Unnamed: 0"], inplace=True)
        test_data.drop(columns=["Unnamed: 0"], inplace=True)

        # Define features and labels
        X_train = train_data.drop(columns=["is_fraud"])
        y_train = train_data["is_fraud"]

        X_test = test_data.drop(columns=["is_fraud"])
        y_test = test_data["is_fraud"]

        # Detect and handle categorical columns
        categorical_columns = X_train.select_dtypes(include=["object"]).columns
        print(f"Categorical columns detected: {categorical_columns.tolist()}")

        # Exclude high-cardinality columns
        cardinality_threshold = 100
        high_cardinality_columns = [
            col for col in categorical_columns if X_train[col].nunique() > cardinality_threshold
        ]
        print(f"High-cardinality columns excluded: {high_cardinality_columns}")

        # Keep only low-cardinality columns for one-hot encoding
        low_cardinality_columns = [
            col for col in categorical_columns if col not in high_cardinality_columns
        ]

        # Apply one-hot encoding to low-cardinality columns
        X_train = pd.get_dummies(X_train, columns=low_cardinality_columns, drop_first=True)
        X_test = pd.get_dummies(X_test, columns=low_cardinality_columns, drop_first=True)

        # Align columns between train and test sets
        X_test = X_test.reindex(columns=X_train.columns, fill_value=0)

        # Simplify high-cardinality columns using counts
        for col in high_cardinality_columns:
            X_train[f"{col}_count"] = X_train[col].map(X_train[col].value_counts())
            X_test[f"{col}_count"] = X_test[col].map(X_train[col].value_counts()).fillna(0)

        # Drop the original high-cardinality columns
        X_train.drop(columns=high_cardinality_columns, inplace=True)
        X_test.drop(columns=high_cardinality_columns, inplace=True)

        print("Categorical columns encoded and simplified. Proceeding with scaling...")

        # Scale the features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # Train the logistic regression model
        print("Training logistic regression model...")
        model = LogisticRegression()
        model.fit(X_train_scaled, y_train)

        # Evaluate the model
        print("Evaluating the model...")
        y_pred = model.predict(X_test_scaled)
        print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
        print("\nClassification Report:\n", classification_report(y_test, y_pred))

        # Save the model
        joblib.dump(model, "../outputs/fraud_model.pkl")
        print("Model saved successfully to '../outputs/fraud_model.pkl'!")

    except Exception as error:
        print(f"An error occurred: {error}")
        raise  # Re-raise the error for debugging purposes

if __name__ == "__main__":
    main()

# Generated by Nicole LeGuern